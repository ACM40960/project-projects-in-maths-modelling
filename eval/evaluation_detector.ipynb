{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca5c1e0d",
   "metadata": {},
   "source": [
    "# Detector Evaluation Notebook\n",
    "\n",
    "This notebook evaluates the **MegaDetector v6** object detection model for animal/vehicle detection across multiple dataset splits, optimizes confidence thresholds, and analyzes performance under domain shift conditions.\n",
    "\n",
    "## Main Steps\n",
    "1. **Confidence Threshold Optimization**\n",
    "   - Sweeps detection confidence values (0.05–0.5) on the validation set.\n",
    "   - Plots **Precision–Recall curve** to help select a balanced high-recall threshold.\n",
    "\n",
    "2. **Evaluation Across Domains & Splits**\n",
    "   - Tests the detector on:\n",
    "     - `cis_val` and `cis_test` (in-domain)\n",
    "     - `trans_val` and `trans_test` (out-of-domain)\n",
    "   - Computes:\n",
    "     - Precision, Recall, F1-score\n",
    "     - mAP@50 and mAP@50-95\n",
    "     - Confusion matrices (saved as PNGs with class names from the dataset YAML)\n",
    "\n",
    "3. **Domain Shift Analysis**\n",
    "   - Compares performance drop from **cis → trans** test sets.\n",
    "   - Highlights best-performing models per split.\n",
    "   - Generates visual summaries:\n",
    "     - F1 by model/domain\n",
    "     - mAP@50 by model/domain\n",
    "     - Precision vs Recall scatter plots\n",
    "     - Domain shift impact bar chart\n",
    "\n",
    "4. **Cropping Animal Detection Outputs**\n",
    "   - Uses the trained detector to generate **per-species cropped images**.\n",
    "   - Skips vehicles and saves crops to:\n",
    "     ```\n",
    "     ../data/megadetector_crops/\n",
    "       ├── train/\n",
    "       │   ├── species_1/\n",
    "       │   ├── species_2/\n",
    "       │   └── background/\n",
    "       └── val/...\n",
    "     ```\n",
    "   - Assigns labels by checking if the **GT box center** falls inside the detector box, otherwise assigns \"background\".\n",
    "\n",
    "5. **Model Export & Threshold Storage**\n",
    "   - Exports MegaDetector v6 to **ONNX** format for deployment.\n",
    "   - Appends chosen optimal threshold to `models/thresholds.txt`.\n",
    "\n",
    "6. **ONNX Inference Benchmark**\n",
    "   - Measures inference speed (ms/img, FPS) on the validation set.\n",
    "   - Logs results to `models/inference_times.csv`.\n",
    "   - Prints sample predictions for manual inspection.\n",
    "\n",
    "## Purpose\n",
    "This notebook validates and analyzes the detector's accuracy, robustness to domain shift, and computational performance, while also preparing **cropped datasets** and **deployment-ready ONNX models** for the next classification stage in the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a19a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.163  Python-3.11.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "YOLOv9c summary (fused): 156 layers, 25,320,790 parameters, 0 gradients, 102.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 606.0452.8 MB/s, size: 122.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\caltech_camera_traps_project\\data\\megadetector_images\\val\\labels.cache... 3736 images, 136 backgrounds, 0 corrupt: 100%|██████████| 3736/3736 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 234/234 [01:00<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3736       3830      0.975       0.95      0.972      0.819\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val59\u001b[0m\n",
      "Ultralytics 8.3.163  Python-3.11.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 863.8581.5 MB/s, size: 119.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\caltech_camera_traps_project\\data\\megadetector_images\\val\\labels.cache... 3736 images, 136 backgrounds, 0 corrupt: 100%|██████████| 3736/3736 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 234/234 [01:01<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3736       3830      0.975       0.95      0.972       0.82\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val60\u001b[0m\n",
      "Ultralytics 8.3.163  Python-3.11.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 848.3314.7 MB/s, size: 106.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\caltech_camera_traps_project\\data\\megadetector_images\\val\\labels.cache... 3736 images, 136 backgrounds, 0 corrupt: 100%|██████████| 3736/3736 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 234/234 [01:02<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3736       3830      0.975       0.95      0.972      0.821\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val61\u001b[0m\n",
      "Ultralytics 8.3.163  Python-3.11.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 971.7549.3 MB/s, size: 110.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\caltech_camera_traps_project\\data\\megadetector_images\\val\\labels.cache... 3736 images, 136 backgrounds, 0 corrupt: 100%|██████████| 3736/3736 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 234/234 [01:05<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3736       3830      0.975       0.95      0.971      0.821\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val62\u001b[0m\n",
      "Ultralytics 8.3.163  Python-3.11.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 706.1387.8 MB/s, size: 105.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\caltech_camera_traps_project\\data\\megadetector_images\\val\\labels.cache... 3736 images, 136 backgrounds, 0 corrupt: 100%|██████████| 3736/3736 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 234/234 [01:04<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3736       3830      0.975       0.95      0.971      0.822\n",
      "Speed: 0.2ms preprocess, 14.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val63\u001b[0m\n",
      "Ultralytics 8.3.163  Python-3.11.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 416.2168.3 MB/s, size: 128.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\caltech_camera_traps_project\\data\\megadetector_images\\val\\labels.cache... 3736 images, 136 backgrounds, 0 corrupt: 100%|██████████| 3736/3736 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 234/234 [01:02<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3736       3830      0.975       0.95       0.97      0.822\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val64\u001b[0m\n",
      "Ultralytics 8.3.163  Python-3.11.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 833.9232.9 MB/s, size: 109.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\caltech_camera_traps_project\\data\\megadetector_images\\val\\labels.cache... 3736 images, 136 backgrounds, 0 corrupt: 100%|██████████| 3736/3736 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 234/234 [01:01<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3736       3830      0.976       0.95       0.97      0.822\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val65\u001b[0m\n",
      "Ultralytics 8.3.163  Python-3.11.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 824.3195.6 MB/s, size: 93.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\caltech_camera_traps_project\\data\\megadetector_images\\val\\labels.cache... 3736 images, 136 backgrounds, 0 corrupt: 100%|██████████| 3736/3736 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 234/234 [01:02<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3736       3830      0.976       0.95      0.969      0.822\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val66\u001b[0m\n",
      "Ultralytics 8.3.163  Python-3.11.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 707.4257.0 MB/s, size: 100.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\caltech_camera_traps_project\\data\\megadetector_images\\val\\labels.cache... 3736 images, 136 backgrounds, 0 corrupt: 100%|██████████| 3736/3736 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 234/234 [01:02<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3736       3830      0.976       0.95      0.968      0.822\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val67\u001b[0m\n",
      "Ultralytics 8.3.163  Python-3.11.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1068.9475.7 MB/s, size: 125.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\caltech_camera_traps_project\\data\\megadetector_images\\val\\labels.cache... 3736 images, 136 backgrounds, 0 corrupt: 100%|██████████| 3736/3736 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 234/234 [01:01<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3736       3830      0.976      0.949      0.967      0.821\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val68\u001b[0m\n",
      "Chosen detector conf = 0.35\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "det2   = YOLO(\"../scripts/train/megadetector_v6/megadetector_augmented/weights/best.pt\")   # your 2-class ckpt\n",
    "# your data.yaml that points at split/images and split/labels\n",
    "DATA_YAML = \"../configs\\model\\megadetector.yaml\"      # 1 = vehicle, 0 = animal\n",
    "assert os.path.exists(DATA_YAML)\n",
    "\n",
    "ths     = np.linspace(0.05, 0.5, 10)\n",
    "prec, rec = [], []\n",
    "\n",
    "for t in ths:\n",
    "    m = det2.val(data=DATA_YAML, split=\"val\", conf=float(t),\n",
    "                 iou=0.50, verbose=False)\n",
    "    prec.append(float(m.box.mp))    # animal precision\n",
    "    rec .append(float(m.box.mr))    # animal recall\n",
    "\n",
    "plt.plot(rec, prec, marker='o'); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "best_t = ths[np.argmax(rec)]        # pick left-most ≥ 0.95 yourself\n",
    "print(f\"Chosen detector conf = {best_t:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f135f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "\n",
    "\n",
    "WEIGHTS = {\n",
    "    \"megadetectorv6\": \"../scripts/train/megadetector_v6/megadetector_augmented/weights/best.pt\"\n",
    "}\n",
    "\n",
    "PROJECT_ROOT = Path(\"C:\\caltech_camera_traps_project\")\n",
    "\n",
    "YAMLS = {\n",
    "    PROJECT_ROOT / \"configs\" / \"megadetector_test\" / \"cis.yaml\"   : \"cis\",\n",
    "    PROJECT_ROOT / \"configs\" / \"megadetector_test\" / \"trans.yaml\": \"trans\",\n",
    "}\n",
    "\n",
    "TRANS_YAML = [y for y, tag in YAMLS.items() if tag == \"trans\"][0]\n",
    "\n",
    "OUT_DIR   = Path(\"detector_stage\");  OUT_DIR.mkdir(exist_ok=True)\n",
    "TRANS_YAML = [y for y, tag in YAMLS.items() if tag == \"trans\"][0]\n",
    "IOU_FIXED = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2b57601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Evaluating model with optimized threshold...\n",
      "\n",
      "📈 Evaluating megadetectorv6...\n",
      "Ultralytics 8.3.163  Python-3.11.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "YOLOv9c summary (fused): 156 layers, 25,320,790 parameters, 0 gradients, 102.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 330.0121.2 MB/s, size: 93.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\caltech_camera_traps_project\\data\\megadetector_images\\trans_val\\labels... 1972 images, 57 backgrounds, 0 corrupt: 100%|██████████| 1972/1972 [00:02<00:00, 980.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\caltech_camera_traps_project\\data\\megadetector_images\\trans_val\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 124/124 [00:30<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1972       2047      0.973      0.927      0.957      0.806\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val54\u001b[0m\n",
      "Class names from YAML: ['animal', 'vehicle']\n",
      "  megadetectorv6_trans_val            P=0.973  R=0.927  F1=0.949\n",
      "Ultralytics 8.3.163  Python-3.11.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 230.688.8 MB/s, size: 112.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\caltech_camera_traps_project\\data\\megadetector_images\\trans_test\\labels... 18553 images, 1782 backgrounds, 0 corrupt: 100%|██████████| 18553/18553 [00:20<00:00, 918.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\caltech_camera_traps_project\\data\\megadetector_images\\trans_test\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1160/1160 [05:01<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      18553      17490      0.964      0.956      0.975      0.816\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val55\u001b[0m\n",
      "Class names from YAML: ['animal', 'vehicle']\n",
      "  megadetectorv6_trans_test           P=0.964  R=0.956  F1=0.960\n",
      "Ultralytics 8.3.163  Python-3.11.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 227.565.5 MB/s, size: 107.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\caltech_camera_traps_project\\data\\megadetector_images\\cis_val\\labels... 1764 images, 79 backgrounds, 0 corrupt: 100%|██████████| 1764/1764 [00:01<00:00, 887.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\caltech_camera_traps_project\\data\\megadetector_images\\cis_val\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 111/111 [00:29<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1764       1783       0.97      0.976      0.982      0.837\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val56\u001b[0m\n",
      "Class names from YAML: ['animal', 'vehicle']\n",
      "  megadetectorv6_cis_val              P=0.970  R=0.976  F1=0.973\n",
      "Ultralytics 8.3.163  Python-3.11.13 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 199.245.4 MB/s, size: 115.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\caltech_camera_traps_project\\data\\megadetector_images\\cis_test\\labels... 12141 images, 96 backgrounds, 0 corrupt: 100%|██████████| 12141/12141 [00:14<00:00, 859.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\caltech_camera_traps_project\\data\\megadetector_images\\cis_test\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 759/759 [03:28<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      12141      12569      0.979      0.973       0.98      0.822\n",
      "Speed: 0.2ms preprocess, 14.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val57\u001b[0m\n",
      "Class names from YAML: ['animal', 'vehicle']\n",
      "  megadetectorv6_cis_test             P=0.979  R=0.973  F1=0.976\n"
     ]
    }
   ],
   "source": [
    "# ───────────────── helpers ─────────────────────\n",
    "def get_class_names_from_yaml(yaml_path):\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    \n",
    "    if 'names' in data:\n",
    "        names = data['names']\n",
    "        if isinstance(names, dict):\n",
    "            # Convert {0: 'opossum', 1: 'raccoon', ...} to ['opossum', 'raccoon', ...]\n",
    "            class_names = [names[i] for i in sorted(names.keys())]\n",
    "            return class_names\n",
    "        elif isinstance(names, list):\n",
    "            return names\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def save_cm(cm, names, tag):\n",
    "    # Normalize the confusion matrix\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    # Handle division by zero (empty rows)\n",
    "    cm_normalized = np.nan_to_num(cm_normalized)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))  # Larger size for better readability\n",
    "    \n",
    "    # Create heatmap with normalized values\n",
    "    sns.heatmap(cm_normalized, \n",
    "                xticklabels=names,  # Use class names instead of indices\n",
    "                yticklabels=names,  # Use class names instead of indices\n",
    "                cmap=\"Blues\", \n",
    "                cbar=True,  # Show colorbar for normalized values\n",
    "                ax=ax,\n",
    "                annot=True,  # Show values in cells\n",
    "                fmt='.2f',   # Format as 2 decimal places\n",
    "                cbar_kws={'label': 'Normalized Count'})\n",
    "    \n",
    "    ax.set_title(f'Confusion Matrix - {tag}')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fn = OUT_DIR / f\"{tag}_cm.png\"\n",
    "    fig.savefig(fn, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    return fn\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Evaluate all models with their best thresholds\n",
    "# ------------------------------------------------------------\n",
    "print(f\"\\n🚀 Evaluating model with optimized threshold...\")\n",
    "\n",
    "# Define evaluation splits\n",
    "SPLITS = [\n",
    "    (TRANS_YAML,                    \"trans\", \"val\"),\n",
    "    (TRANS_YAML,                    \"trans\", \"test\"),  # trans_test\n",
    "    *[(y, t, \"val\")  for y, t in YAMLS.items() if t == \"cis\"],   # cis_val\n",
    "    *[(y, t, \"test\") for y, t in YAMLS.items() if t == \"cis\"],   # cis_test\n",
    "]\n",
    "\n",
    "model_objects = {}  # Cache loaded models\n",
    "rows = []\n",
    "\n",
    "for model_name, weight_path in WEIGHTS.items():\n",
    "    print(f\"\\n📈 Evaluating {model_name}...\")\n",
    "    \n",
    "    # Load model once and cache it\n",
    "    if model_name not in model_objects:\n",
    "        model_objects[model_name] = YOLO(weight_path)\n",
    "    model = model_objects[model_name]\n",
    "    \n",
    "    # Get the best threshold for this model\n",
    "    best_conf = 0.35\n",
    "    \n",
    "    # Evaluate on all splits\n",
    "    for yaml_path, dom, split in SPLITS:\n",
    "        tag = f\"{model_name}_{dom}_{split}\"\n",
    "        \n",
    "        # Run evaluation\n",
    "        met = model.val(data=yaml_path, split=split,\n",
    "                       conf=float(best_conf), iou=IOU_FIXED,\n",
    "                       verbose=False, plots=True)\n",
    "        \n",
    "        # Save confusion matrix\n",
    "        try:\n",
    "            # Newer Ultralytics: metric.confusion_matrix.matrix\n",
    "            cm = met.confusion_matrix.matrix\n",
    "        except AttributeError:\n",
    "            # Older builds: metric.box.confusion_matrix.matrix\n",
    "            print(\"FAILED\")\n",
    "            cm = met.box.confusion_matrix.matrix\n",
    "        \n",
    "        try:\n",
    "            # Get class names from the dataset YAML\n",
    "            class_names = get_class_names_from_yaml(yaml_path)\n",
    "            print(f\"Class names from YAML: {class_names}\")\n",
    "            \n",
    "            if cm is not None and cm.sum() > 0:\n",
    "                cm_png = save_cm(cm, class_names, tag)  # Use YAML class names\n",
    "            else:\n",
    "                print(f\"Empty confusion matrix for {tag}\")\n",
    "                cm_png = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error with confusion matrix: {e}\")\n",
    "            cm_png = None\n",
    "        \n",
    "        # Calculate metrics\n",
    "        precision = float(met.box.mp)\n",
    "        recall = float(met.box.mr)\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "        \n",
    "        # Store results\n",
    "        row = {\n",
    "            \"model\"      : model_name,\n",
    "            \"domain\"     : dom,\n",
    "            \"split\"      : split,\n",
    "            \"conf\"       : round(best_conf, 2),\n",
    "            \"precision\"  : precision,\n",
    "            \"recall\"     : recall,\n",
    "            \"F1\"         : f1,\n",
    "            \"mAP50\"      : float(met.box.map50),\n",
    "            \"mAP50-95\"   : float(met.box.map),\n",
    "            \"cm_png\"     : cm_png.name,\n",
    "            \"eval_time\"  : datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        rows.append(row)\n",
    "        \n",
    "        print(f\"  {tag:35s} P={precision:.3f}  R={recall:.3f}  F1={f1:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2981c344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✔︎ Main metrics written to C:\\caltech_camera_traps_project\\eval\\detector_stage\\summary_metrics.csv\n",
      "✔︎ Detailed analysis written to C:\\caltech_camera_traps_project\\eval\\detector_stage\\detailed_analysis.csv\n",
      "\n",
      "📊 EVALUATION SUMMARY:\n",
      "============================================================\n",
      "\n",
      "🎯 Performance by Domain:\n",
      "                 F1                    mAP50                  \n",
      "               mean std    max    min   mean std    max    min\n",
      "domain split                                                  \n",
      "cis    test   0.976 NaN  0.976  0.976  0.980 NaN  0.980  0.980\n",
      "       val    0.973 NaN  0.973  0.973  0.982 NaN  0.982  0.982\n",
      "trans  test   0.960 NaN  0.960  0.960  0.975 NaN  0.975  0.975\n",
      "       val    0.949 NaN  0.949  0.949  0.957 NaN  0.957  0.957\n",
      "\n",
      "🏆 Best Models per Split:\n",
      "  trans_val : megadetectorv6                 (F1=0.949)\n",
      "  trans_test: megadetectorv6                 (F1=0.960)\n",
      "  cis_val : megadetectorv6                 (F1=0.973)\n",
      "  cis_test: megadetectorv6                 (F1=0.976)\n",
      "\n",
      "🔄 Domain Shift Analysis:\n",
      "  megadetectorv6                :  +1.7% drop (cis: 0.976 → trans: 0.960)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔︎ Evaluation summary plot saved to detector_stage\\evaluation_summary.png\n",
      "\n",
      "🎉 Evaluation complete! Check detector_stage for all results.\n",
      "\n",
      "📋 Final Results DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>domain</th>\n",
       "      <th>split</th>\n",
       "      <th>conf</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>mAP50</th>\n",
       "      <th>mAP50-95</th>\n",
       "      <th>cm_png</th>\n",
       "      <th>eval_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>megadetectorv6</td>\n",
       "      <td>trans</td>\n",
       "      <td>val</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.972706</td>\n",
       "      <td>0.926648</td>\n",
       "      <td>0.949118</td>\n",
       "      <td>0.957226</td>\n",
       "      <td>0.805949</td>\n",
       "      <td>megadetectorv6_trans_val_cm.png</td>\n",
       "      <td>2025-07-23 15:20:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>megadetectorv6</td>\n",
       "      <td>trans</td>\n",
       "      <td>test</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.963596</td>\n",
       "      <td>0.956059</td>\n",
       "      <td>0.959813</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.816402</td>\n",
       "      <td>megadetectorv6_trans_test_cm.png</td>\n",
       "      <td>2025-07-23 15:26:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>megadetectorv6</td>\n",
       "      <td>cis</td>\n",
       "      <td>val</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.969513</td>\n",
       "      <td>0.975908</td>\n",
       "      <td>0.972700</td>\n",
       "      <td>0.982211</td>\n",
       "      <td>0.837487</td>\n",
       "      <td>megadetectorv6_cis_val_cm.png</td>\n",
       "      <td>2025-07-23 15:27:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>megadetectorv6</td>\n",
       "      <td>cis</td>\n",
       "      <td>test</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.978850</td>\n",
       "      <td>0.973242</td>\n",
       "      <td>0.976038</td>\n",
       "      <td>0.979707</td>\n",
       "      <td>0.822318</td>\n",
       "      <td>megadetectorv6_cis_test_cm.png</td>\n",
       "      <td>2025-07-23 15:31:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model domain split  conf  precision    recall        F1     mAP50  \\\n",
       "0  megadetectorv6  trans   val  0.35   0.972706  0.926648  0.949118  0.957226   \n",
       "1  megadetectorv6  trans  test  0.35   0.963596  0.956059  0.959813  0.974539   \n",
       "2  megadetectorv6    cis   val  0.35   0.969513  0.975908  0.972700  0.982211   \n",
       "3  megadetectorv6    cis  test  0.35   0.978850  0.973242  0.976038  0.979707   \n",
       "\n",
       "   mAP50-95                            cm_png            eval_time  \n",
       "0  0.805949   megadetectorv6_trans_val_cm.png  2025-07-23 15:20:39  \n",
       "1  0.816402  megadetectorv6_trans_test_cm.png  2025-07-23 15:26:24  \n",
       "2  0.837487     megadetectorv6_cis_val_cm.png  2025-07-23 15:27:13  \n",
       "3  0.822318    megadetectorv6_cis_test_cm.png  2025-07-23 15:31:21  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 3. Save and analyze results\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Save main summary\n",
    "csv_path = OUT_DIR / \"summary_metrics.csv\"\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "# Save additional detailed analysis\n",
    "detailed_path = OUT_DIR / \"detailed_analysis.csv\"\n",
    "df_detailed = df.copy()\n",
    "\n",
    "# Add performance comparisons\n",
    "df_detailed['domain_shift'] = df_detailed.apply(\n",
    "    lambda row: 'in_domain' if row['domain'] == 'cis' else 'out_domain', axis=1\n",
    ")\n",
    "\n",
    "# Calculate relative performance (compared to best model per split)\n",
    "for split_combo in df_detailed[['domain', 'split']].drop_duplicates().values:\n",
    "    dom, spl = split_combo\n",
    "    mask = (df_detailed['domain'] == dom) & (df_detailed['split'] == spl)\n",
    "    best_f1 = df_detailed[mask]['F1'].max()\n",
    "    df_detailed.loc[mask, 'relative_f1'] = df_detailed.loc[mask, 'F1'] / best_f1\n",
    "\n",
    "df_detailed.to_csv(detailed_path, index=False)\n",
    "\n",
    "print(f\"\\n✔︎ Main metrics written to {csv_path.resolve()}\")\n",
    "print(f\"✔︎ Detailed analysis written to {detailed_path.resolve()}\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(f\"\\n📊 EVALUATION SUMMARY:\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Summary by domain\n",
    "print(\"\\n🎯 Performance by Domain:\")\n",
    "domain_summary = df.groupby(['domain', 'split']).agg({\n",
    "    'F1': ['mean', 'std', 'max', 'min'],\n",
    "    'mAP50': ['mean', 'std', 'max', 'min']\n",
    "}).round(3)\n",
    "print(domain_summary)\n",
    "\n",
    "# Best performing models per split\n",
    "print(f\"\\n🏆 Best Models per Split:\")\n",
    "for split_combo in df[['domain', 'split']].drop_duplicates().values:\n",
    "    dom, spl = split_combo\n",
    "    mask = (df['domain'] == dom) & (df['split'] == spl)\n",
    "    best_row = df[mask].loc[df[mask]['F1'].idxmax()]\n",
    "    print(f\"  {dom}_{spl:4s}: {best_row['model']:30s} (F1={best_row['F1']:.3f})\")\n",
    "\n",
    "# Domain shift analysis\n",
    "print(f\"\\n🔄 Domain Shift Analysis:\")\n",
    "cis_test = df[(df['domain'] == 'cis') & (df['split'] == 'test')]\n",
    "trans_test = df[(df['domain'] == 'trans') & (df['split'] == 'test')]\n",
    "\n",
    "for model in df['model'].unique():\n",
    "    cis_f1 = cis_test[cis_test['model'] == model]['F1'].iloc[0]\n",
    "    trans_f1 = trans_test[trans_test['model'] == model]['F1'].iloc[0]\n",
    "    drop = ((cis_f1 - trans_f1) / cis_f1) * 100\n",
    "    print(f\"  {model:30s}: {drop:+5.1f}% drop (cis: {cis_f1:.3f} → trans: {trans_f1:.3f})\")\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: F1 scores by model and domain\n",
    "ax1 = axes[0, 0]\n",
    "test_data = df[df['split'] == 'test']\n",
    "pivot_f1 = test_data.pivot(index='model', columns='domain', values='F1')\n",
    "pivot_f1.plot(kind='bar', ax=ax1, rot=45)\n",
    "ax1.set_title('F1 Score by Model and Domain (Test Set)')\n",
    "ax1.set_ylabel('F1 Score')\n",
    "ax1.legend(title='Domain')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: mAP50 scores\n",
    "ax2 = axes[0, 1]\n",
    "pivot_map = test_data.pivot(index='model', columns='domain', values='mAP50')\n",
    "pivot_map.plot(kind='bar', ax=ax2, rot=45)\n",
    "ax2.set_title('mAP50 by Model and Domain (Test Set)')\n",
    "ax2.set_ylabel('mAP50')\n",
    "ax2.legend(title='Domain')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Precision vs Recall\n",
    "ax3 = axes[1, 0]\n",
    "for domain in df['domain'].unique():\n",
    "    domain_data = test_data[test_data['domain'] == domain]\n",
    "    ax3.scatter(domain_data['recall'], domain_data['precision'], \n",
    "               label=domain, alpha=0.7, s=100)\n",
    "ax3.set_xlabel('Recall')\n",
    "ax3.set_ylabel('Precision')\n",
    "ax3.set_title('Precision vs Recall (Test Set)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Domain shift impact\n",
    "ax4 = axes[1, 1]\n",
    "models = []\n",
    "domain_drops = []\n",
    "for model in df['model'].unique():\n",
    "    try:\n",
    "        cis_f1 = cis_test[cis_test['model'] == model]['F1'].iloc[0]\n",
    "        trans_f1 = trans_test[trans_test['model'] == model]['F1'].iloc[0]\n",
    "        drop = ((cis_f1 - trans_f1) / cis_f1) * 100\n",
    "        models.append(model)\n",
    "        domain_drops.append(drop)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "ax4.bar(range(len(models)), domain_drops, color='lightcoral', alpha=0.7)\n",
    "ax4.set_xticks(range(len(models)))\n",
    "ax4.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax4.set_ylabel('Performance Drop (%)')\n",
    "ax4.set_title('Domain Shift Impact (CIS → Trans)')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"evaluation_summary.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✔︎ Evaluation summary plot saved to {OUT_DIR / 'evaluation_summary.png'}\")\n",
    "print(f\"\\n🎉 Evaluation complete! Check {OUT_DIR} for all results.\")\n",
    "\n",
    "# Display final dataframe\n",
    "print(f\"\\n📋 Final Results DataFrame:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84bcac03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species ids: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13]\n",
      "vehicle ids: [11] \n",
      "\n",
      "WARNING \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "WARNING \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "✅ All crops finished → C:\\caltech_camera_traps_project\\data\\megadetector_crops\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import cv2, os, random\n",
    "\n",
    "# ── CONFIG ────────────────────────────────────────────────\n",
    "YOLO_SPLITS = {\n",
    "    \"train\": (\"../data/yolo_images/train_balanced/images\", \"../data/yolo_images/train_balanced/labels\"),\n",
    "    \"val\"  : (\"../data/yolo_images/val/images\",   \"../data/yolo_images/val/labels\"),\n",
    "}\n",
    "DET_WGT   = \"../scripts/train/megadetector_v6/megadetector_augmented/weights/best.pt\"\n",
    "CONF_DET  = 0.35                         # high-recall value you chose\n",
    "DATA_YAML   = \"../configs/model/yolo_balanced.yaml\"\n",
    "BG_NAME   = \"background\"\n",
    "OUT_ROOT  = Path(\"../data/megadetector_crops/\")     # will hold train/ val/ subdirs\n",
    "# ──────────────────────────────────────────────────────────\n",
    "\n",
    "with open(DATA_YAML) as f:\n",
    "    names_yaml = yaml.safe_load(f)[\"names\"]        # list or {id: name}\n",
    "\n",
    "\n",
    "if isinstance(names_yaml, dict):                   # dict?  sort by key\n",
    "    names = [names_yaml[i] for i in sorted(names_yaml)]\n",
    "else:                                              # already list\n",
    "    names = names_yaml\n",
    "\n",
    "vehicle_ids = [i for i,n in enumerate(names) if n.lower() in (\"car\")]\n",
    "species_ids = [i for i in range(len(names)) if i not in vehicle_ids]\n",
    "\n",
    "print(\"species ids:\", species_ids)\n",
    "print(\"vehicle ids:\", vehicle_ids, \"\\n\")\n",
    "\n",
    "# 2) prepare directories -------------------------------------\n",
    "for split in YOLO_SPLITS:\n",
    "    for cls_name in [names[i] for i in species_ids] + [BG_NAME]:\n",
    "        (OUT_ROOT/split/cls_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 3) helper ---------------------------------------------------\n",
    "def iou_xyxy(a,b):\n",
    "    xA=max(a[0],b[0]); yA=max(a[1],b[1])\n",
    "    xB=min(a[2],b[2]); yB=min(a[3],b[3])\n",
    "    inter=max(0,xB-xA)*max(0,yB-yA)\n",
    "    if inter==0: return 0\n",
    "    union=(a[2]-a[0])*(a[3]-a[1])+(b[2]-b[0])*(b[3]-b[1])-inter\n",
    "    return inter/union\n",
    "\n",
    "det = YOLO(DET_WGT, task=\"detect\"); det.conf = CONF_DET\n",
    "\n",
    "# 4) generate crops ------------------------------------------\n",
    "for split, (img_dir, lbl_dir) in YOLO_SPLITS.items():\n",
    "    img_dir, lbl_dir = Path(img_dir), Path(lbl_dir)\n",
    "\n",
    "    for res in det.predict(img_dir, imgsz=640, verbose=False):\n",
    "        img = cv2.imread(res.path); h,w = img.shape[:2]\n",
    "        lbl_path = lbl_dir / Path(res.path).with_suffix(\".txt\").name\n",
    "        if not lbl_path.exists():\n",
    "            print(\"missing label file:\", lbl_path); continue\n",
    "\n",
    "        # -- load GT species boxes ----------------------------\n",
    "        gt_boxes, gt_ids = [], []\n",
    "        with open(lbl_path) as f:\n",
    "            for ln in f:\n",
    "                cid, xc, yc, bw, bh = map(float, ln.split())\n",
    "                cid=int(cid)\n",
    "                if cid in vehicle_ids:              # skip vehicle GT\n",
    "                    continue\n",
    "                gx1=(xc-bw/2)*w; gy1=(yc-bh/2)*h\n",
    "                gx2=(xc+bw/2)*w; gy2=(yc+bh/2)*h\n",
    "                gt_boxes.append((gx1,gy1,gx2,gy2)); gt_ids.append(cid)\n",
    "\n",
    "        # -- walk detector boxes ------------------------------\n",
    "        for box, cls_det in zip(res.boxes.xyxy.cpu().numpy(),\n",
    "                        res.boxes.cls.cpu().numpy()):\n",
    "            if int(cls_det) == 1:              # detector says \"vehicle\"  → skip\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = box.astype(int)\n",
    "\n",
    "            # ----------- NEW centre-inside-GT logic ----------------\n",
    "            label_id = None\n",
    "            for (gx1, gy1, gx2, gy2), gid in zip(gt_boxes, gt_ids):\n",
    "                cx, cy = (gx1 + gx2) / 2, (gy1 + gy2) / 2   # GT box centre point\n",
    "                if x1 <= cx <= x2 and y1 <= cy <= y2:       # centre inside detector box?\n",
    "                    label_id = gid                          # use that species\n",
    "                    break                                   # stop after first match\n",
    "\n",
    "            label_name = names[label_id] if label_id is not None else BG_NAME\n",
    "            # -------------------------------------------------------\n",
    "\n",
    "            out = (\n",
    "                OUT_ROOT / split / label_name /\n",
    "                f\"{Path(res.path).stem}_{x1}_{y1}.jpg\"\n",
    "            )\n",
    "            cv2.imwrite(str(out), img[y1:y2, x1:x2])\n",
    "\n",
    "print(\"✅ All crops finished →\", OUT_ROOT.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6de5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.163  Python-3.11.13 torch-2.5.1+cu121 CPU (AMD Ryzen 9 7940HS w/ Radeon 780M Graphics)\n",
      "YOLOv9c summary (fused): 156 layers, 25,320,790 parameters, 0 gradients, 102.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\scripts\\train\\megadetector_v6\\megadetector_augmented\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (49.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.61...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  9.5s, saved as '..\\scripts\\train\\megadetector_v6\\megadetector_augmented\\weights\\best.onnx' (96.8 MB)\n",
      "\n",
      "Export complete (10.7s)\n",
      "Results saved to \u001b[1mC:\\caltech_camera_traps_project\\scripts\\train\\megadetector_v6\\megadetector_augmented\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\scripts\\train\\megadetector_v6\\megadetector_augmented\\weights\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=..\\scripts\\train\\megadetector_v6\\megadetector_augmented\\weights\\best.onnx imgsz=640 data=C:\\caltech_camera_traps_project\\configs\\model\\megadetector.yaml  \n",
      "Visualize:       https://netron.app\n",
      " exported → C:\\caltech_camera_traps_project\\models\\megadetectorv6.onnx\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from ultralytics import YOLO   \n",
    "\n",
    "ckpt_path = Path(\"../scripts/train/megadetector_v6/megadetector_augmented/weights/best.pt\")   # adjust if needed\n",
    "out_dir   = Path(\"../models\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model = YOLO(str(ckpt_path))\n",
    "onnx_name = out_dir / \"megadetectorv6.onnx\"\n",
    "model.export(format=\"onnx\", imgsz=640, simplify=True, dynamic=True, nms=True)\n",
    "(ckpt_path.parent / \"best.onnx\").rename(onnx_name)\n",
    "\n",
    "print(f\" exported → {onnx_name.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45748eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Line added to C:\\caltech_camera_traps_project\\models\\thresholds.txt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define file path\n",
    "txt_path =  Path(\"../models/thresholds.txt\")  # replace with your .txt file name\n",
    "new_line = \"megadetector_v6: 0.35\"\n",
    "\n",
    "# Append the line\n",
    "with open(txt_path, \"a\") as f:\n",
    "    f.write(f\"{new_line}\\n\")\n",
    "\n",
    "print(f\"✅ Line added to {txt_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62156bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# Benchmark one exported ONNX model on the test set and log time\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "out_dir = Path(\"../models\")\n",
    "# ── 1. CONFIG ────────────────────────────────────────────────\n",
    "MODEL_NAME  = \"megadetectorv6\"           # ← change to \"megadetector_v6\"\n",
    "CONF_TH     = 0.35                       # ← change to 0.15 for MD-v6\n",
    "ONNX_PATH   = out_dir / f\"{MODEL_NAME}.onnx\"\n",
    "TEST_DIR    = Path(\"../data/megadetector_images/val/images\")   # folder of *.jpg / *.png\n",
    "\n",
    "LOG_CSV     = Path(\"../models/inference_times.csv\")\n",
    "LOG_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ── 2. RUN & TIME  ───────────────────────────────────────────\n",
    "model = YOLO(ONNX_PATH, task=\"detect\")\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "results = model.predict(source=str(TEST_DIR),\n",
    "                        imgsz=640,\n",
    "                        conf=CONF_TH,\n",
    "                        save=False,\n",
    "                        verbose=False)\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "num_imgs     = len(results)\n",
    "total_secs   = t1 - t0\n",
    "avg_secs     = total_secs / num_imgs\n",
    "fps          = 1 / avg_secs\n",
    "\n",
    "print(f\"\\n{MODEL_NAME}: {num_imgs} images  |  {total_secs:6.2f} s total  \"\n",
    "      f\"→  {avg_secs*1000:5.1f} ms/img  ({fps:5.1f} FPS)\")\n",
    "\n",
    "# ── 3. LOG TO CSV  ───────────────────────────────────────────\n",
    "row = {\n",
    "    \"model\"        : MODEL_NAME,\n",
    "    \"images\"       : num_imgs,\n",
    "    \"conf_thresh\"  : CONF_TH,\n",
    "    \"total_sec\"    : round(total_secs, 3),\n",
    "    \"sec_per_img\"  : round(avg_secs, 4),\n",
    "    \"fps\"          : round(fps, 2),\n",
    "}\n",
    "\n",
    "if LOG_CSV.exists():\n",
    "    df_log = pd.read_csv(LOG_CSV)\n",
    "    # drop any previous entry for this model so the latest timing wins\n",
    "    df_log = df_log[df_log[\"model\"] != MODEL_NAME]\n",
    "    df_log = pd.concat([df_log, pd.DataFrame([row])], ignore_index=True)\n",
    "else:\n",
    "    df_log = pd.DataFrame([row])\n",
    "\n",
    "df_log.to_csv(LOG_CSV, index=False)\n",
    "print(f\"✅ timing appended → {LOG_CSV.resolve()}\")\n",
    "\n",
    "\n",
    "# 3. Peek at the first few predictions -------------------------------------\n",
    "print(f\"\\nFound {len(results)} images in {TEST_DIR}\")\n",
    "for i, r in enumerate(results[:3]):        # just display first 3\n",
    "    print(f\"\\n🖼️  Image {i+1}: {Path(r.path).name}\")\n",
    "    for cls, conf, xyxy in zip(r.boxes.cls, r.boxes.conf, r.boxes.xyxy):\n",
    "        label = r.names[int(cls)]\n",
    "        x1, y1, x2, y2 = map(int, xyxy)\n",
    "        print(f\"   • {label:12s} {conf:5.2f}   box=({x1},{y1})–({x2},{y2})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-wildlife",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
